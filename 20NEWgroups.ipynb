{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# dirname_number = 0\n",
    "# file_number = 1\n",
    "# writefile = open('NewGroup_data.txt', 'w')\n",
    "# for dirname, subdir, filename in os.walk('C:/Users/karis/Desktop/latently/20news-bydate-train/', topdown=True):\n",
    "#     if dirname != \"C:/Users/karis/Desktop/latently/20news-bydate-train/\":\n",
    "#         for file_nam in filename:\n",
    "#             f = os.path.join(dirname, file_nam)\n",
    "#             with open(f,'r') as main:\n",
    "#                 contents = main.readlines()\n",
    "#                 writefile.write(\"{}\\t{}\\t{}\\n\".format(file_number, contents, dirname_number))\n",
    "#                 file_number = file_number+1\n",
    "#         dirname_number = dirname_number+1\n",
    "# writefile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_names = []\n",
    "for dirname, subdir, filename in os.walk('C:/Users/karis/Desktop/latently/20news-bydate-train/', topdown=False):\n",
    "     for i in  subdir:\n",
    "            group_names.append(i)\n",
    "group_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>review</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['From: mathew &lt;mathew@mantis.co.uk&gt;\\n', 'Subj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['From: mathew &lt;mathew@mantis.co.uk&gt;\\n', 'Subj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['From: I3150101@dbstu1.rz.tu-bs.de (Benedikt ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['From: mathew &lt;mathew@mantis.co.uk&gt;\\n', 'Subj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['From: strom@Watson.Ibm.Com (Rob Strom)\\n', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_id                                             review  group_id\n",
       "0          1  ['From: mathew <mathew@mantis.co.uk>\\n', 'Subj...         0\n",
       "1          2  ['From: mathew <mathew@mantis.co.uk>\\n', 'Subj...         0\n",
       "2          3  ['From: I3150101@dbstu1.rz.tu-bs.de (Benedikt ...         0\n",
       "3          4  ['From: mathew <mathew@mantis.co.uk>\\n', 'Subj...         0\n",
       "4          5  ['From: strom@Watson.Ibm.Com (Rob Strom)\\n', '...         0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas import Series, DataFrame\n",
    "group_train = pd.read_csv(\"C:\\Users\\karis\\NewGroup_data.txt\", sep=\"\\t\", header = None, names= ['phrase_id', 'review', 'group_id'])\n",
    "group_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>review</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['From: decay@cbnewsj.cb.att.com (dean.kaflowi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['From: cfaehl@vesta.unm.edu (Chris Faehl)\\n',...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['From: mathew &lt;mathew@mantis.co.uk&gt;\\n', 'Subj...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['From: dps@nasa.kodak.com (Dan Schaertel,,,)\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['From: halat@panther.bears (Jim Halat)\\n', 'S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_id                                             review  group_id\n",
       "0          1  ['From: decay@cbnewsj.cb.att.com (dean.kaflowi...         0\n",
       "1          2  ['From: cfaehl@vesta.unm.edu (Chris Faehl)\\n',...         0\n",
       "2          3  ['From: mathew <mathew@mantis.co.uk>\\n', 'Subj...         0\n",
       "3          4  ['From: dps@nasa.kodak.com (Dan Schaertel,,,)\\...         0\n",
       "4          5  ['From: halat@panther.bears (Jim Halat)\\n', 'S...         0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_test = pd.read_csv(\"C:\\Users\\karis\\NewGroup_data_test.txt\", sep=\"\\t\", header = None, names= ['phrase_id', 'review', 'group_id'])\n",
    "group_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 4)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maping cateogories to train dataframe\n",
    "\n",
    "group_train['category'] = group_train.group_id.map({0:'alt', 1:'comp',2:'comp', 3:'comp', 4:'comp',5:'comp',6:'misc', 7:'rec', 8:'rec',9:'rec', 10:'rec', 11:'sci',\n",
    "                                    12:'sci', 13:'sci', 14:'sci', 15:'religion', \n",
    "                                    16:'politics', 17:'politics', 18:'politics', 19:'religion'})\n",
    "\n",
    "# maping cateogories to test dataframe\n",
    "\n",
    "group_test['category'] = group_test.group_id.map({0:'alt', 1:'comp',2:'comp', 3:'comp', 4:'comp',5:'comp',6:'misc', 7:'rec', 8:'rec',9:'rec', 10:'rec', 11:'sci',\n",
    "                                    12:'sci', 13:'sci', 14:'sci', 15:'religion', \n",
    "                                    16:'politics', 17:'politics', 18:'politics', 19:'religion'})\n",
    "\n",
    "group_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7876L,)\n",
      "(5244L,)\n"
     ]
    }
   ],
   "source": [
    "# selecting categories \n",
    "group_train_category = group_train[(group_train.category == 'comp') | (group_train.category == 'rec') | (group_train.category == 'politics') | (group_train.category == 'religion')]\n",
    "group_test_category = group_test[(group_test.category == 'comp') | (group_test.category == 'rec') | (group_test.category == 'politics') | (group_test.category == 'religion')]\n",
    "\n",
    "\n",
    "# spliting data into input X_train and output Y_train\n",
    "X_train = group_train_category.review\n",
    "# Y_train = group_train_category.category\n",
    "\n",
    "# spliting data into input X_train and output Y_train\n",
    "X_test = group_test_category.review\n",
    "# Y_test = group_test_category.category\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7876, 111641)\n",
      "(5244, 111641)\n"
     ]
    }
   ],
   "source": [
    "# use CountVectorizer to create document-term matrices from X_train and X_test\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "\n",
    "\n",
    "# fit and transform X_train\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_train_dtm.shape)\n",
    "print(X_test_dtm.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7876L,)\n",
      "(5244L,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "Label_encoded = LabelEncoder()\n",
    "Y_train_label_encoded = Label_encoded.fit_transform(group_train_category['category'].values)\n",
    "Y_test_label_encoded = Label_encoded.fit_transform(group_test_category['category'].values)\n",
    "\n",
    "\n",
    "# Y_train_label_encoded = np.vstack(Y_train_label_encoded)\n",
    "# Y_test_label_encoded = np.vstack(Y_test_label_encoded)\n",
    "\n",
    "print(Y_train_label_encoded.shape)\n",
    "print(Y_test_label_encoded.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_test(vect):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "\n",
    "    # fit and transform X_train\n",
    "\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "    LR = LogisticRegression(multi_class= 'ovr')\n",
    "\n",
    "    LR.fit(X_train_dtm, Y_train_label_encoded)\n",
    "\n",
    "    Y_predicted = LR.predict(X_test_dtm)\n",
    "\n",
    "    print ('accracy:', accuracy_score(Y_test_label_encoded, Y_predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accracy:', 0.94508009153318073)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accracy:', 0.9416475972540046)\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accracy:', 0.93821510297482835)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "tokenize_test(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_test_svm(vect):\n",
    "    from sklearn import svm\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "\n",
    "    # fit and transform X_train\n",
    "\n",
    "    X_train_dtm = vect.fit_transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "\n",
    "    lin_clf = svm.LinearSVC()\n",
    "    lin_clf.fit(X_train_dtm, Y_train_label_encoded)\n",
    "    Y_predicted = lin_clf.predict(X_test_dtm)\n",
    "\n",
    "    print ('accracy:', accuracy_score(Y_test_label_encoded, Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accracy:', 0.93688024408848203)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "tokenize_test_svm(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accracy:', 0.94107551487414187)\n"
     ]
    }
   ],
   "source": [
    "# include 1-grams and 2-grams\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "tokenize_test_svm(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "\n",
    "# lin_clf = svm.LinearSVC()\n",
    "# lin_clf.fit(X_train_dtm, Y_train_label_encoded)\n",
    "# Y_predicted = lin_clf.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accracy:', 0.93688024408848203)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# print ('accracy:', accuracy_score(Y_test_label_encoded, Y_predicted))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
