{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>review</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[b'From: mathew &lt;mathew@mantis.co.uk&gt;\\n', b'Su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[b'From: mathew &lt;mathew@mantis.co.uk&gt;\\n', b'Su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[b'From: I3150101@dbstu1.rz.tu-bs.de (Benedikt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[b'From: mathew &lt;mathew@mantis.co.uk&gt;\\n', b'Su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[b'From: strom@Watson.Ibm.Com (Rob Strom)\\n', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_id                                             review  group_id\n",
       "0          1  [b'From: mathew <mathew@mantis.co.uk>\\n', b'Su...         0\n",
       "1          2  [b'From: mathew <mathew@mantis.co.uk>\\n', b'Su...         0\n",
       "2          3  [b'From: I3150101@dbstu1.rz.tu-bs.de (Benedikt...         0\n",
       "3          4  [b'From: mathew <mathew@mantis.co.uk>\\n', b'Su...         0\n",
       "4          5  [b'From: strom@Watson.Ibm.Com (Rob Strom)\\n', ...         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch Csv train traing data\n",
    "group_train = pd.read_csv(\"input/Group20_combined_data/NewGroup_data_train.txt\", sep=\"\\t\", header = None, names= ['phrase_id', 'review', 'group_id'])\n",
    "group_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase_id</th>\n",
       "      <th>review</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[b'From: decay@cbnewsj.cb.att.com (dean.kaflow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[b'From: cfaehl@vesta.unm.edu (Chris Faehl)\\n'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[b'From: mathew &lt;mathew@mantis.co.uk&gt;\\n', b'Su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[b'From: dps@nasa.kodak.com (Dan Schaertel,,,)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[b'From: halat@panther.bears (Jim Halat)\\n', b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   phrase_id                                             review  group_id\n",
       "0          1  [b'From: decay@cbnewsj.cb.att.com (dean.kaflow...         0\n",
       "1          2  [b'From: cfaehl@vesta.unm.edu (Chris Faehl)\\n'...         0\n",
       "2          3  [b'From: mathew <mathew@mantis.co.uk>\\n', b'Su...         0\n",
       "3          4  [b'From: dps@nasa.kodak.com (Dan Schaertel,,,)...         0\n",
       "4          5  [b'From: halat@panther.bears (Jim Halat)\\n', b...         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch Csv test data \n",
    "group_test = pd.read_csv(\"input/Group20_combined_data/NewGroup_data_test.txt\", sep=\"\\t\", header = None, names= ['phrase_id', 'review', 'group_id'])\n",
    "group_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7532, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maping cateogories to train dataframe\n",
    "\n",
    "group_train['category'] = group_train.group_id.map({0:'alt', 1:'comp',2:'comp', 3:'comp', 4:'comp',5:'comp',6:'misc', 7:'rec', 8:'rec',9:'rec', 10:'rec', 11:'sci',\n",
    "                                    12:'sci', 13:'sci', 14:'sci', 15:'religion', \n",
    "                                    16:'politics', 17:'politics', 18:'politics', 19:'religion'})\n",
    "\n",
    "# maping cateogories to test dataframe\n",
    "\n",
    "group_test['category'] = group_test.group_id.map({0:'alt', 1:'comp',2:'comp', 3:'comp', 4:'comp',5:'comp',6:'misc', 7:'rec', 8:'rec',9:'rec', 10:'rec', 11:'sci',\n",
    "                                    12:'sci', 13:'sci', 14:'sci', 15:'religion', \n",
    "                                    16:'politics', 17:'politics', 18:'politics', 19:'religion'})\n",
    "\n",
    "group_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# selecting categories \n",
    "group_train_category = group_train[(group_train.category == 'comp') | (group_train.category == 'rec') | (group_train.category == 'politics') | (group_train.category == 'religion')]\n",
    "group_test_category = group_test[(group_test.category == 'comp') | (group_test.category == 'rec') | (group_test.category == 'politics') | (group_test.category == 'religion')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatinating Train and Test datasets\n",
    "\n",
    "group_train_test_category = pd.concat([group_train_category, group_test_category])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "Label_encoded = LabelEncoder()\n",
    "\n",
    "\n",
    "# Hot-encode the target category\n",
    "Y_label_encoded = Label_encoded.fit_transform(group_train_test_category['category'].values)\n",
    "Y = np_utils.to_categorical(Y_label_encoded)\n",
    "\n",
    "# combined X data\n",
    "X = group_train_test_category.review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 172367 unique tokens.\n",
      "Shape of data tensor: (13120, 500)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "X_word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(X_word_index))\n",
    "\n",
    "X_data = pad_sequences(X_sequences, maxlen=500)\n",
    "\n",
    "print('Shape of data tensor:', X_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splitting Test and Train data\n",
    "X_train =X_data[:10000]\n",
    "X_test = X_data[10000:]\n",
    "Y_train = Y[:10000]\n",
    "Y_test =Y[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# word2vec model with gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('C:/Users/karis/Desktop/latently/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.syn0\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras import losses\n",
    "from keras.utils import np_utils\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-28-4bcb2d88e5c5>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-28-4bcb2d88e5c5>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    model.add(Conv1D(nb_filter=32, filter_length=3, border_mode= 'same' , activation= 'relu', input_length=10000))\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Implemt CNN with pre-trained Embedding layer\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=weights.shape[0], output_dim=weights.shape[1], weights=[weights])\n",
    "model.add(Conv1D(nb_filter=32, filter_length=3, border_mode= 'same' , activation= 'relu', input_length=10000))\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation= 'relu' ))\n",
    "model.add(Dense(4, activation= 'softmax' ))\n",
    "model.compile(loss= 'categorical_crossentropy', optimizer= 'adam' , metrics=[ 'accuracy' ])\n",
    "print(model.summary())\n",
    "# Fit the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), nb_epoch=10, batch_size=128, verbose=1)\n",
    "# Final evaluation of the model\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
